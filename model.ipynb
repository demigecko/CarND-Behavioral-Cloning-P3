{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my code\n",
    "\n",
    "# set the parameters \n",
    "correction =0.2; # the steering angle correction\n",
    "validation_split = 0.2; \n",
    "batch_size = 256;\n",
    "\n",
    "# import the packages\n",
    "import os, platform, glob, csv, cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "import math\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Conv2D, Dropout, AveragePooling2D, Activation, MaxPooling2D, BatchNormalization \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "# I combined all the drive.log files into one manually \n",
    "csv_path = 'C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Ho_track2\\\\driving_log.csv'\n",
    "# I collected all the images in the same folder\n",
    "IMG_path = 'C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Ho_track2\\\\IMG\\\\'\n",
    "\n",
    "# the model based on nVidia end-to-end driving model with ustomized activation and dropout\n",
    "def model_nvidia(act='relu', d=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((50, 20), (0, 0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(lambda x: x/255-0.5, output_shape=(90, 320, 3)))\n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(48, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(64, (3,3), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(64, (1,1), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(50, activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(10, activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "# the generator \n",
    "def generator(samples, batch_size=256):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                for j in range(3):\n",
    "                    factor=[0, 1, -1]    \n",
    "                    #filename = IMG_path + batch_sample[j].split('/')[-1]  #Unix or Mac\n",
    "                    filename = batch_sample[j].split('/')[-1] # window \n",
    "                    # includes left, center, and right images with corresponding steering angle correction\n",
    "                    measurement = round(float(batch_sample[3]) + factor[j]*correction,3); \n",
    "                    image = cv2.imread(filename) \n",
    "                    images.append(image)\n",
    "                    angles.append(measurement)\n",
    "                    # produce the mirror images \n",
    "                    images.append(cv2.flip(image,1))\n",
    "                    angles.append(measurement*(-1))\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# data input \n",
    "samples = []\n",
    "with open(csv_path) as csvfile:\n",
    "    reader = csv.reader(csvfile,delimiter=',')\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "# set the train samples (0.8) and validation samples (0.2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "# calculate the numbers of steps and stpes_per_epoch\n",
    "number_valid_steps = math.ceil(len(validation_samples*3*2)/batch_size)\n",
    "steps_per_epoch = math.ceil(len(train_samples*3*2)/batch_size)\n",
    "\n",
    "# run the model \n",
    "model = model_nvidia(act='relu', d=0.5)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.summary()\n",
    "\n",
    "print(\"# of samples:\", len(samples*3*2))\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"# valid samples:\", number_valid_steps)\n",
    "print(\"# per epoch:\", steps_per_epoch)\n",
    "\n",
    "#model = load_model('model.h5')\n",
    "history_object=model.fit_generator(train_generator,\n",
    "                                   steps_per_epoch=steps_per_epoch,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   validation_steps=number_valid_steps, \n",
    "                                   epochs=20, verbose=1)\n",
    "model.save('model.h5')\n",
    "                               \n",
    "# print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "# plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
