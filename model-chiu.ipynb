{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, platform, glob, csv, cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Conv2D, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "def read_sim_logs(csv_paths):\n",
    "    \"\"\"\n",
    "    Reads each `.csv` file and stores the image file paths and measurement values to a list of dictionaries.\n",
    "    :param csv_paths: list of file paths to CSV files created by the simulator.\n",
    "    :return: list of dictionaries containing image files and measurements from the simulator at each sample.\n",
    "    \"\"\"\n",
    "    log_file_name = 'driving_log.csv'\n",
    "    \n",
    "    lines = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    if not isinstance(csv_paths, list):\n",
    "        csv_paths = [csv_paths]\n",
    "    for i_path, path in enumerate(csv_paths):\n",
    "        csv_file_path = os.path.join(path, log_file_name)\n",
    "        print('Loading data from \"{}\"...'.format(csv_file_path))\n",
    "        img_path = path +\"IMG/\"\n",
    "        print(path)\n",
    "        with open(csv_file_path, 'rt') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            for line in reader:\n",
    "                if line is None:\n",
    "                    # empty line\n",
    "                    continue\n",
    "                lines.append(line)\n",
    "                \n",
    "                center_image_path = os.path.join(img_path,  line[0].split('/')[-1])\n",
    "                left_image_path = os.path.join(img_path,  line[1].split('/')[-1])\n",
    "                right_image_path = os.path.join(img_path,  line[2].split('/')[-1])\n",
    "\n",
    "                center_angle = float(line[3])\n",
    "                left_angle = center_angle + angle_correction\n",
    "                right_angle = center_angle - angle_correction\n",
    "\n",
    "                labels.extend([center_angle, left_angle, right_angle])\n",
    "                filenames.extend([center_image_path, left_image_path, right_image_path])\n",
    "    return lines, filenames, labels\n",
    "\n",
    "def read_image(log_path, path_to_imgs):\n",
    "    image_path = get_image_path(log_path, path_to_imgs)\n",
    "    # cv2 reads to BGR\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "def image_normalization(pixel_value):\n",
    "    # image normalization for pixel values to be zero mean and SD of 1\n",
    "    result = pixel_value / 255.0 - 0.5\n",
    "    return result\n",
    "\n",
    "def sim_model(act='elu', d=0.5, debug=False):\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((65, 25), (0, 0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(normalize_pixels, output_shape=(70, 320, 3)))\n",
    "    if debug:\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        return model\n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(48, (5,5), strides=(2,2), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(64, (3,3), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Conv2D(64, (3,3), activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(50, activation=act))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(10, activation=act))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def augmented_image(image, label, proba=0.5):\n",
    "    ''' \n",
    "    method for adding random distortion to dataset images, including random brightness adjust, and a random\n",
    "    vertical shift of the horizon position\n",
    "    '''\n",
    "    new_img = image.astype(float)\n",
    "    # 1) randomly flip image horizontally and reverse label\n",
    "    if np.random.rand() > proba:\n",
    "        new_img = cv2.flip(new_img, 1)\n",
    "        label = -label\n",
    "    # 2) random brightness\n",
    "    new_img = brighten_image(new_img)\n",
    "    # 3) random shadow\n",
    "    new_img = shadow_image(new_img)\n",
    "    # 4) random horizon shift\n",
    "    new_img = shift_horizon(new_img)\n",
    "    return new_img.astype(np.uint8), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columen: [center image/ left image/ right image/ steering[-1,1]/ throttle[0,1]/ break[always 0] /speed[0,30]] \n",
    "# read the image from the given paths in driving_log.csv\n",
    "import os, platform, glob, csv, cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Conv2D, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "FilePath = ['C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Hans_track2_t2\\\\driving_log.csv',\n",
    "            'C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Hans_track2\\\\driving_log.csv',\n",
    "            'C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Hans_track1\\\\driving_log.csv', ]\n",
    "\n",
    "current_path = ['C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Hans_track2_t2\\\\IMG\\\\',\n",
    "                'C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Hans_track2\\\\IMG\\\\',\n",
    "                'C:\\\\Users\\\\hsiny\\\\GitHub\\\\data\\\\Hans_track1\\\\IMG\\\\',]\n",
    "\n",
    "images =[]\n",
    "measurements=[]\n",
    "correction=0.3\n",
    "for j in range(3):\n",
    "    lines=[]\n",
    "    with open(FilePath[j]) as csvfile:\n",
    "        spamreader = csv.reader(csvfile)        \n",
    "        for line in spamreader:\n",
    "            lines.append(line)\n",
    "        csvfile.close()\n",
    "        for line in lines: \n",
    "            for i in range(3):\n",
    "                factor=[0, 1, -1]\n",
    "                source_path = line[i]\n",
    "                filename = source_path.split('/')[-1]\n",
    "                current_paths = current_path[j] + filename \n",
    "                image=cv2.imread(current_paths)\n",
    "                #image=cv2.imread(current_paths, cv2.IMREAD_GRAYSCALE)\n",
    "                images.append(image)\n",
    "                measurement = float(line[3])\n",
    "                measurements.append(round(measurement + factor[i]*correction,3)) \n",
    "\n",
    "augmented_images, augmented_measurements = [],[]\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement*(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28026, 28026]\n"
     ]
    }
   ],
   "source": [
    "print([len(augmented_images), len(augmented_measurements)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 320, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_images[10000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_measurements[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_bins = 20\n",
    "n, bins, patches = plt.hist(measurements, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28026/28026 [==============================] - 11s 409us/step - loss: 0.3829\n",
      "Epoch 2/5\n",
      " 7296/28026 [======>.......................] - ETA: 8s - loss: 0.1734"
     ]
    }
   ],
   "source": [
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((65, 25), (0, 0)), input_shape=(160, 320, 3)))\n",
    "model.add(Lambda(lambda x: x/255 -0.5, output_shape=(70, 320, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=128 ,epochs=5)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e210f2052c24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m history_object = model.fit_generator(train_generator, samples_per_epoch =\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "    len(train_samples), validation_data = \n",
    "    validation_generator,\n",
    "    nb_val_samples = len(validation_samples), \n",
    "    nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_47 to have shape (10,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-b99d98bdb02c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_47 to have shape (10,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# columen: [center image/ left image/ right image/ steering[-1,1]/ throttle[0,1]/ break[always 0] /speed[0,30]] \n",
    "# read the image from the given paths in driving_log.csv\n",
    "import os, platform, glob, csv, cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Conv2D, Dropout, AveragePooling2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "FilePath = 'C:\\\\Users\\\\hsiny\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data\\\\Hans_track1\\\\driving_log.csv'\n",
    "lines=[]\n",
    "with open(FilePath) as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for line in spamreader:\n",
    "        lines.append(line)\n",
    "images =[]\n",
    "measurements=[]\n",
    "for line in lines: \n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path= 'C:\\\\Users\\\\hsiny\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\data\\\\Hans_track1\\\\IMG\\\\' + filename \n",
    "    image=cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement) \n",
    "    \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255 -0.5, input_shape=(160,320,3)))\n",
    "model.add(Conv2D(filters = 6, kernel_size = 5, strides = 5, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "model.add(Conv2D(filters = 6, kernel_size = 5,strides = 5, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 120, activation = 'relu'))\n",
    "model.add(Dense(units = 84, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'softmax'))\n",
    "#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(X_train ,y_train, epochs = 12)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.0",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
